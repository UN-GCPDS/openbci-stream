
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Appendix 4 - System latencies &#8212; OpenBCI-Stream  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../_static/favico.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Appendix 3 - Raspberry PI as server acquisition" href="A3-server-based_acquisition.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 0;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
}
</style><div class="section" id="Appendix-4---System-latencies">
<h1>Appendix 4 - System latencies<a class="headerlink" href="#Appendix-4---System-latencies" title="Permalink to this headline">¶</a></h1>
<p>Brain computer interface (BCI) systems must process neural signals with consistent timing in order to support adequate system performance. Thus, it is important to have the capability to determine whether a particular BCI configuration (hardware or software) provides adequate timing performance for a particular experiment. This appendix describes the latencies present when using <em>OpenBCI-Stream</em> for acquisition and distributed EEG signal processing <a class="footnote-reference brackets" href="#wilson2010procedure" id="id1">1</a>.</p>
<center><p><img alt="9aac212775ca4d83a8a9bdf12dbce411" src="../_images/latencies.png" /></p>
</center><div class="section" id="Latency-Definitions">
<h2>Latency Definitions<a class="headerlink" href="#Latency-Definitions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Real-time">
<h3>Real-time<a class="headerlink" href="#Real-time" title="Permalink to this headline">¶</a></h3>
<p>The term <strong>real-time</strong> is used somewhat loosely, indicating only that the BCI system is able to process an entire block of data and update the output device before the next sample block is ready for processing. However, the degree to which the BCI system can be considered real-time is dependent on many factors, including the operating system, computer hardware specifications, and output device hardware. Furthermore, even if the mean overall processing and output time is less than the sample
block size, large variability in this timing can significantly affect BCI performance, and must therefore be accounted for <a class="footnote-reference brackets" href="#wilson2010procedure" id="id2">1</a>.</p>
</div>
<div class="section" id="Sample-block-size-and-Block-duration-(T_2---T_{-1})">
<h3>Sample block size and Block duration (<span class="math notranslate nohighlight">\(T_2\)</span> - <span class="math notranslate nohighlight">\(T_{-1}\)</span>)<a class="headerlink" href="#Sample-block-size-and-Block-duration-(T_2---T_{-1})" title="Permalink to this headline">¶</a></h3>
<p>Ideally, the block duration should be identical to the sample block size; however, inconsistencies in operating system timing may interrupt and delay data acquisition, causing the time period between data blocks to be different than the actual block size, introducing a timing jitter.</p>
<p>The block duration is the primary indicator of the system’s ability to perform online signal processing in a BCI experiment. It is important to realize that the block duration is measured from the perspective of the software, and is not the same as the block size. That is, the block duration will never typically be less than the block size (i.e., the length of a block of data acquired from the ADC), but it can be longer than the block size if the system latency is longer than the block size.</p>
</div>
<div class="section" id="ADC-buffer-(T_{-1}---T_{-2})">
<h3>ADC buffer (<span class="math notranslate nohighlight">\(T_{-1}\)</span> - <span class="math notranslate nohighlight">\(T_{-2}\)</span>)<a class="headerlink" href="#ADC-buffer-(T_{-1}---T_{-2})" title="Permalink to this headline">¶</a></h3>
<p>The ADC (analog to digital converter) buffer needs to be filled with an amount of raw data before digitize, this factor can be configured from WiFi Shield properties. Over Serial protocol, this latency can be related to RFduino protocol transmission.</p>
</div>
<div class="section" id="Acquisition-(T_0---T_{-1})">
<h3>Acquisition (<span class="math notranslate nohighlight">\(T_0\)</span> - <span class="math notranslate nohighlight">\(T_{-1}\)</span>)<a class="headerlink" href="#Acquisition-(T_0---T_{-1})" title="Permalink to this headline">¶</a></h3>
<p>This is the delay between the time that the final sample in a sample block is digitized to when the sample block has been acquired by the software and is available to the software for processing. Depending on configuration, this latency may comprise physical signal delay in the amplifier, digitization, transmission from the ADC to the PC, and processing time inside a hardware driver.</p>
</div>
</div>
<div class="section" id="Methods-for-measuring-latencies">
<h2>Methods for measuring latencies<a class="headerlink" href="#Methods-for-measuring-latencies" title="Permalink to this headline">¶</a></h2>
<p>All measures performed will use timestamps and software methods, this is possible due to the Kakfa protocol that registers production timestamps and other ones that are packed with the data stream. For this specific debugging, the acquisition runs on a <strong>Raspberry Pi 4</strong> and the data stream is <strong>collected remotely</strong>.</p>
<p>This measures can be done with this simple script that use an existing data stream:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[182]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">get_latencies</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="n">openbci_consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span><span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">HOST</span><span class="si">}</span><span class="s1">:9092&#39;</span><span class="p">],</span>
                                         <span class="n">value_deserializer</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">,</span>
                                         <span class="n">auto_offset_reset</span><span class="o">=</span><span class="s1">&#39;latest&#39;</span><span class="p">)</span>
    <span class="n">openbci_consumer</span><span class="o">.</span><span class="n">subscribe</span><span class="p">([</span><span class="s1">&#39;eeg&#39;</span><span class="p">])</span>

    <span class="n">latencies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">openbci_consumer</span><span class="p">:</span>

        <span class="n">reference</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">timestamp</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">timestamp_binary</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">][</span><span class="s1">&#39;timestamp.binary&#39;</span><span class="p">])</span>
        <span class="n">timestamp_binary_consume</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">][</span><span class="s1">&#39;timestamp.binary.consume&#39;</span><span class="p">])</span>
        <span class="n">timestamp_eeg</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">][</span><span class="s1">&#39;timestamp.eeg&#39;</span><span class="p">])</span>

        <span class="n">latencies</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;Block duration&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;Binary produced&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">reference</span> <span class="o">-</span> <span class="n">timestamp_binary</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;Binary consumed&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">reference</span> <span class="o">-</span> <span class="n">timestamp_binary_consume</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;EEG produced&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">reference</span> <span class="o">-</span> <span class="n">timestamp_eeg</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;_EEG consumed&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">reference</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">latencies</span><span class="p">[</span><span class="s1">&#39;Block duration&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="n">samples</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;done&#39;</span><span class="p">)</span>
            <span class="k">break</span>
    <span class="n">latencies</span><span class="p">[</span><span class="s1">&#39;Block duration&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">latencies</span><span class="p">[</span><span class="s1">&#39;Block duration&#39;</span><span class="p">])</span><span class="o">*</span><span class="mi">1000</span>

    <span class="k">return</span> <span class="n">latencies</span>
</pre></div>
</div>
</div>
<p>For a configuration of 100 ms blocks, 8 channels and 1000 samples per second:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[219]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">latencies_100</span> <span class="o">=</span> <span class="n">get_latencies</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">show_latencies</span><span class="p">(</span><span class="n">latencies_100</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;for 100 ms block duration at 1000 SPS and 8 channels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_A4-latencies_7_0.png" src="../_images/notebooks_A4-latencies_7_0.png" />
</div>
</div>
<p>This plot shows the cumulative latency from the first process (acquisition) to deserialization of the EEG.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[220]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">latencies_500</span> <span class="o">=</span> <span class="n">get_latencies</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">show_latencies</span><span class="p">(</span><span class="n">latencies_500</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;for 500 ms block duration at 1000 SPS and 8 channels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_A4-latencies_9_0.png" src="../_images/notebooks_A4-latencies_9_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[221]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">latencies_1000</span> <span class="o">=</span> <span class="n">get_latencies</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">show_latencies</span><span class="p">(</span><span class="n">latencies_1000</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;for 1000 ms block duration at 1000 SPS and 8 channels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_A4-latencies_10_0.png" src="../_images/notebooks_A4-latencies_10_0.png" />
</div>
</div>
</div>
<div class="section" id="Additional-latency-for-distributed-systems">
<h2>Additional latency for distributed systems<a class="headerlink" href="#Additional-latency-for-distributed-systems" title="Permalink to this headline">¶</a></h2>
<p>Since the data transmission is not instantaneous, access to the stream remotely adds a latency that can measure mainly in two features.</p>
<div class="section" id="NTP-offset">
<h3>NTP offset<a class="headerlink" href="#NTP-offset" title="Permalink to this headline">¶</a></h3>
<p>Before measuring the latency in two different systems is needed to get the systems synchronized, the implementation used for this test is synchronized with the Network Time Protocol server running on Raspberry Pi.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[157]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">client</span> <span class="o">=</span> <span class="n">ntplib</span><span class="o">.</span><span class="n">NTPClient</span><span class="p">()</span>
<span class="n">ntp_offset</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">HOST</span><span class="p">)</span><span class="o">.</span><span class="n">offset</span> <span class="o">*</span> <span class="mi">1000</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; NTP offset: </span><span class="si">{</span><span class="n">ntp_offset</span> <span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 NTP offset: 4.21 ms
</pre></div></div>
</div>
</div>
<div class="section" id="Distributed-latency">
<h3>Distributed latency<a class="headerlink" href="#Distributed-latency" title="Permalink to this headline">¶</a></h3>
<p>This latency is related with Kafka, is the time from the EEG producer (on Raspberry) to EEG consumed in the remote system.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[158]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distributed: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">latencies_100</span><span class="p">[</span><span class="s1">&#39;_EEG consumed&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> ms&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Distributed: 2.444 ms
</pre></div></div>
</div>
<p>The final <code class="docutils literal notranslate"><span class="pre">offset</span></code> is:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[227]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">latencies_100</span><span class="p">[</span><span class="s1">&#39;_EEG consumed&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="n">ntp_offset</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total offset: </span><span class="si">{</span><span class="n">offset</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total offset: 6.66 ms
</pre></div></div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">offset</span></code> affects all latencies except the block duration.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[222]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_latencies</span><span class="p">(</span><span class="n">latencies_100</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;for 100 ms block duration at 1000 SPS and 8 channels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_A4-latencies_19_0.png" src="../_images/notebooks_A4-latencies_19_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Results">
<h2>Results<a class="headerlink" href="#Results" title="Permalink to this headline">¶</a></h2>
<p>Has been proved that OpenBCI-Stream can distribute EEG signal (with metadata) in approximately the 50% of the block duration, this performance allows the user through asynchronous data processing the development of real-time multipurpose BCI systems.</p>
<p>Real-time issues are paradigm-agnostic since some implementations require windows of 2.5 seconds <a class="footnote-reference brackets" href="#mora2020brain" id="id3">2</a> or more, even short time control signals like P300 need commonly too many trials <a class="footnote-reference brackets" href="#nicolas-alonso-brain-2012" id="id4">3</a> which in practice is an even bigger window.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>_</p></th>
<th class="head"><p>Latency for 100 ms block</p></th>
<th class="head"><p>Jitter for 100 ms block</p></th>
<th class="head"><p>Latency for 500 ms block</p></th>
<th class="head"><p>Jitter for 500 ms block</p></th>
<th class="head"><p>Latency for 1000 ms block</p></th>
<th class="head"><p>Jitter for 1000 ms block</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Block duration</p></td>
<td><p>100.07 ms</p></td>
<td><p>5.72 ms</p></td>
<td><p>500.15 ms</p></td>
<td><p>15.20 ms</p></td>
<td><p>1000.36 ms</p></td>
<td><p>20.04 ms</p></td>
</tr>
<tr class="row-odd"><td><p>Total latency</p></td>
<td><p>56.00 ms</p></td>
<td><p>4.01 ms</p></td>
<td><p>236.72 ms</p></td>
<td><p>11.11 ms</p></td>
<td><p>453.53 ms</p></td>
<td><p>13.03 ms</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p><dl class="footnote brackets">
<dt class="label" id="wilson2010procedure"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>J Adam Wilson, Jürgen Mellinger, Gerwin Schalk, and Justin Williams. A procedure for measuring latencies in brain–computer interfaces. <em>IEEE transactions on biomedical engineering</em>, 57(7):1785–1797, 2010.</p>
</dd>
<dt class="label" id="mora2020brain"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Aldo Mora-Sánchez, Alfredo-Aram Pulini, Antoine Gaume, Gérard Dreyfus, and François-Benoît Vialatte. A brain–computer interface for the continuous, real-time monitoring of working memory load in real-world environments. <em>Cognitive neurodynamics</em>, pages 1–21, 2020.</p>
</dd>
<dt class="label" id="nicolas-alonso-brain-2012"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>Luis Fernando Nicolas-Alonso and Jaime Gomez-Gil. Brain Computer Interfaces, a Review. <em>Sensors</em>, 12(2):1211–1279, January 2012. URL: <a class="reference external" href="http://www.mdpi.com/1424-8220/12/2/1211">http://www.mdpi.com/1424-8220/12/2/1211</a> (visited on 2021-05-04), <a class="reference external" href="https://doi.org/10.3390/s120201211">doi:10.3390/s120201211</a>.</p>
</dd>
</dl>
</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo.svg" alt="Logo"/>
            </a></p>
<h3><a href="../index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="00-installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-hardware_configurations.html">Hardware configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-kafka_configuration.html">Kafka configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-data_acquisition.html">Data Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-board_modes.html">Board modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-stream_markers.html">Stream markers with Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-command_line_interface.html">Command line interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-data_storage_handler.html">Data storage handler</a></li>
<li class="toctree-l1"><a class="reference internal" href="A1-raw_cleaning.html">Appendix 1 - Raw data processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="A2-electrodes_impedance.html">Appendix 2 - Measuring Electrode Impedance</a></li>
<li class="toctree-l1"><a class="reference internal" href="A3-server-based_acquisition.html">Appendix 3 - Raspberry PI as server acquisition</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Appendix 4 - System latencies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Latency-Definitions">Latency Definitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Methods-for-measuring-latencies">Methods for measuring latencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Additional-latency-for-distributed-systems">Additional latency for distributed systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Results">Results</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019-2021, Yeison Cardona.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/notebooks/A4-latencies.ipynb"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>openbci_stream.utils.hdf5 &#8212; OpenBCI-Stream  documentation</title>
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../../_static/favico.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for openbci_stream.utils.hdf5</h1><div class="highlight"><pre>
<span></span>&quot;&quot;&quot;
====================
Data storage handler
====================

This data handler use [PyTables](https://www.pytables.org/) that is built on top
of the HDF5 library, using the Python language and the NumPy package. It
features an object-oriented interface that, combined with C extensions for the
performance-critical parts of the code (generated using Cython), makes it a
fast, yet extremely easy to use tool for interactively browse, process and
search very large amounts of data. One important feature of
[PyTables](https://www.pytables.org/) is that it optimizes memory and disk
resources so that data takes much less space (specially if on-flight compression
is used) than other solutions such as relational or object oriented databases.

For examples and descriptions refers to documentation:
`Data storage handler &lt;../07-data_storage_handler.ipynb&gt;`_
&quot;&quot;&quot;

import json
import logging
from datetime import datetime, date
from functools import cached_property
from typing import Dict, Any, Optional, Text, List, TypeVar, Union, Tuple
import ntplib
import mne
import tables
import numpy as np
from scipy.interpolate import interp1d

try:
    import pyedflib
except:
    logging.warning(&quot;&#39;pyedflib&#39; is needed for export to EDF&quot;)
# Custom type var
timestamp_ = TypeVar(&#39;timesamp&#39;, float, np.float)

mne.set_log_level(&#39;CRITICAL&#39;)


# ----------------------------------------------------------------------
<div class="viewcode-block" id="np2json_serializer"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.np2json_serializer">[docs]</a>def np2json_serializer(obj):
    &quot;&quot;&quot;hdf5 handler needs Python classic data types.&quot;&quot;&quot;
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, datetime):
        return obj.__str__()</div>


# ----------------------------------------------------------------------
<div class="viewcode-block" id="interpolate_datetime"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.interpolate_datetime">[docs]</a>def interpolate_datetime(timestamp: List[timestamp_], length: Optional[int] = None) -&gt; List[timestamp_]:
    &quot;&quot;&quot;Interpolate uncomplete timestamp list.

    The input timestamp list must be a list of timestamps separated by zeros,
    this script will complete the missing timestamps. This primary purpose is to
    complete the list generated from stream data when only it has a sample rate
    and acquired times.

    Parameters
    ----------
    timestamp
        An array with timestamps and zeros.
    length
        The length of the final timestamp array, if not defined then will be the
        same size of the input timestamp.

    Returns
    -------
    timestamp
        An array with interpolated timestamps.
    &quot;&quot;&quot;

    if length is None:
        length = timestamp.shape[0]

    nonzero = np.nonzero(timestamp)[0]

    x = nonzero * (length / nonzero[-1])
    interp = interp1d(x, timestamp[nonzero], fill_value=&quot;extrapolate&quot;)
    # args = np.arange(-nonzero[0], length - nonzero[0])
    args = np.arange(length)

    timestamp = interp(args)
    return timestamp</div>


########################################################################
<div class="viewcode-block" id="HDF5Writer"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer">[docs]</a>class HDF5Writer:
    &quot;&quot;&quot;This HDF5 data handler was pre-configured for the architecture of
    acquired EEG data.

    This module can be used like an instance e.g.

    &gt;&gt;&gt; writer = HDF5Writer(&#39;file.h5&#39;)
    &gt;&gt;&gt; writer.add_marker(&#39;LEFT&#39;, datetime.now().timestamp())
    &gt;&gt;&gt; writer.close()

    or can be used with the `with` control-flow structure e.g.

    &gt;&gt;&gt; with HDF5Writer(&#39;file.h5&#39;) as write:
            writer.add_marker(&#39;LEFT&#39;, datetime.now().timestamp())

    Parameters
    ----------
    filename
        Path where the edf file will be created.
    &quot;&quot;&quot;

    # ----------------------------------------------------------------------
    def __init__(self, filename: str) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        if filename.endswith(&#39;h5&#39;):
            self.filename = f&#39;{filename}&#39;
        else:
            self.filename = f&#39;{filename}.h5&#39;

        self.channels = None
        self._open()

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.close"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.close">[docs]</a>    def close(self) -&gt; None:
        &quot;&quot;&quot;Close the file handler.

        Before to close, add some extra values into the header.
        &quot;&quot;&quot;
        if self.array_eeg is None:
            header2 = {&#39;shape&#39;: 0}
            logging.warning(&#39;EEG is empty&#39;)
        else:
            header2 = {&#39;shape&#39;: self.array_eeg.shape}
        if self.host_ntp:
            client = ntplib.NTPClient()
            header2.update(
                {&#39;end-offset&#39;: client.request(self.host_ntp).offset * 1000})

        self.array_hdr.append([json.dumps(header2, default=np2json_serializer)])
        self.f.close()</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_timestamp"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_timestamp">[docs]</a>    def add_timestamp(self, timestamp: timestamp_) -&gt; None:
        &quot;&quot;&quot;Add a list of timestamps to the hdf5 file.

        The use of this method is not recommended, instead, it must be used
        `add_eeg` that includes a validation.
        &quot;&quot;&quot;
        self.array_dtm.append(timestamp)</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_header"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_header">[docs]</a>    def add_header(self, header: Dict[str, Any], host: Optional[str] = None) -&gt; None:
        &quot;&quot;&quot;Set the header for hdf5 file.

        A header is basically a dictionary with all kinds of useful information.
        There are required keys for some specific methods.

        MNE objects requiere:
          * **montage:** str with montage name, e.g. &#39;standard_1020&#39;.
          * **channels:** dict with keys as channel index and values as channel
            name, e.g `{1: &#39;FP1&#39;, 2: &#39;FP2&#39;, 3: &#39;F7&#39;}`.
          * **sample_rate:** int sample rate for acuiered signal, e.g `1000`.

        EDF objects requiere (In addition to the above):
          * **admincode:** str with the admincode.
          * **birthdate:** date object with the the birthdate of the patient.
          * **equipment:** str thats describes the measurement equpipment.
          * **gender:** int with the the gender, 1 is male, 0 is female.
          * **patientcode:** str with the patient code.
          * **patientname:** str with the patient name.
          * **patient_additional:** str with the additional patient information.
          * **recording_additional:** str wit the additional recording information.
          * **technician:** str with the technicians name.
        &quot;&quot;&quot;
        if host:
            client = ntplib.NTPClient()
            header.update(
                {&#39;start-offset&#39;: client.request(host).offset * 1000, })
        self.host_ntp = host

        self.array_hdr.append([json.dumps(header, default=np2json_serializer)])</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_marker"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_marker">[docs]</a>    def add_marker(self, marker: Any, timestamp: timestamp_) -&gt; None:
        &quot;&quot;&quot;Add a pair of marker-timestamp to the hdf5 file.

        There is some difference between markers and annotations:

          * Markers are writed as time series.
          * Annotations are writed as a list of events.
          * Markers are mainly for repetitions of the same event.
          * Annotations can describe a complex event with a custom duration and
            long description, e.g artifacts.
        &quot;&quot;&quot;
        self.array_mkr.append(
            [json.dumps([timestamp, marker], default=np2json_serializer)])</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_markers"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_markers">[docs]</a>    def add_markers(self, markers: Dict[str, List[timestamp_]]) -&gt; None:
        &quot;&quot;&quot;Add a set of markers to the hdf5 file.

        This method is used to write a set of markers at the same time, works
        with a dictionary object, with keys as marker and values as a list of
        timestamps

        Example
        -------

        &gt;&gt;&gt; markes = {&#39;LEFT&#39;: [1603898187.226709,
                               1603898197.226709,
                               1603898207.226709],
                      &#39;RIGHT&#39;: [1603898192.226709,
                                1603898202.226709,
                                1603898212.226709]
                      }
        &gt;&gt;&gt; add_markers(markers)
        &quot;&quot;&quot;

        for marker in markers:
            for timestamp in markers[marker]:
                self.add_marker(marker, timestamp)</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_annotation"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_annotation">[docs]</a>    def add_annotation(self, onset: timestamp_, duration: int = 0, description: str = &#39;&#39;) -&gt; None:
        &quot;&quot;&quot;Add EDF annotations to the hdf5 file.

        These annotations will be exported with EDF file and follow the format
        defined by `pyedflib &lt;https://pyedflib.readthedocs.io/en/latest/ref/edfwriter.html#pyedflib.EdfWriter.writeAnnotation&gt;`_.

        There is some difference between markers and annotations:

          * Markers are writed as time series.
          * Annotations are writed as a list of events.
          * Markers are mainly for repetitions of the same event.
          * Annotations can describe a complex event with a custom duration and
            long description, e.g artifacts.

        Parameters
        ----------
        onset
            Timestamp for annotation.
        duration
            The duration of the event.
        description
            The description of the annotation.
        &quot;&quot;&quot;

        self.array_anno.append(
            [json.dumps([onset, duration, description], default=np2json_serializer)])</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_eeg"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_eeg">[docs]</a>    def add_eeg(self, eeg_data: np.ndarray, timestamp: Optional[timestamp_] = None) -&gt; None:
        &quot;&quot;&quot;Add EEG data to hdf5 file, optionally adds timestamps.

        The first time this method is called the number of channels of EEG is
        configured, and cannot be changed.

        Parameters
        ----------
        eeg_data
            An array of shape (`channels, time`)
        timestamp
            A single timestamp corresponding to the last sample acquired.
        &quot;&quot;&quot;
        if self.array_eeg is None:
            self.channels, _ = eeg_data.shape
            atom_eeg = tables.Float64Atom()
            self.array_eeg = self.f.create_earray(
                self.f.root, &#39;eeg_data&#39;, atom_eeg, shape=(self.channels, 0), title=&#39;EEG time series&#39;)

        if self.channels != eeg_data.shape[0]:
            logging.warning(
                f&#39;The number of channels {self.channels} can not be changed!&#39;)
            return

        self.array_eeg.append(eeg_data)

        if isinstance(timestamp, (np.ndarray, list, tuple)):

            assert len(
                timestamp) == eeg_data.shape[1], f&quot;Is not recommended add data and timestamp from different sizes. {len(timestamp)} != {eeg_data.shape[1]}&quot;
            self.add_timestamp(timestamp)

        elif timestamp != None:
            timestamp_ = np.zeros(eeg_data.shape[1])
            timestamp_[-1] = timestamp
            self.add_timestamp(timestamp_)</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Writer.add_aux"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Writer.add_aux">[docs]</a>    def add_aux(self, aux_data: np.ndarray) -&gt; None:
        &quot;&quot;&quot;Write AUX data into the hdf5 file.

        The shape of aux data cannot be changed after the first write.

        Parameters
        ----------
        aux_data
            OpenBCI aux data defined in `board modes &lt;../notebooks/04-board_modes.ipynb&gt;`_
        &quot;&quot;&quot;

        if self.array_aux is None:
            channels, _ = aux_data.shape
            atom_eeg = tables.Float64Atom()
            self.array_aux = self.f.create_earray(
                self.f.root, &#39;aux_data&#39;, atom_eeg, shape=(channels, 0), title=&#39;EEG time series&#39;)

        self.array_aux.append(aux_data)</div>

    # ----------------------------------------------------------------------
    def __enter__(self) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        return self

    # ----------------------------------------------------------------------
    def _open(self) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.f = tables.open_file(self.filename, mode=&#39;w&#39;)

        atom_dtm = tables.Float64Atom()
        atom_json = tables.StringAtom(itemsize=2**15)

        self.array_hdr = self.f.create_earray(
            self.f.root, &#39;header&#39;, atom_json, shape=(0,), title=&#39;HEADER&#39;)
        self.array_eeg = None
        self.array_aux = None
        self.array_dtm = self.f.create_earray(
            self.f.root, &#39;timestamp&#39;, atom_dtm, shape=(0,), title=&#39;EEG timestamp&#39;)
        self.array_mkr = self.f.create_earray(
            self.f.root, &#39;markers&#39;, atom_json, shape=(0,), title=&#39;EEG markers&#39;)
        self.array_anno = self.f.create_earray(
            self.f.root, &#39;annotations&#39;, atom_json, shape=(0,), title=&#39;EEG annotations&#39;)

    # ----------------------------------------------------------------------
    def __exit__(self, exc_type: Text, exc_val: Text, exc_tb: Text) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.close()</div>


########################################################################
<div class="viewcode-block" id="HDF5Reader"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Reader">[docs]</a>class HDF5Reader:
    &quot;&quot;&quot;Objects created with `HDF5Writer` can be opened with `HDF5Reader`.

    This class support export to other formmats like
    `MNE epochs &lt;https://mne.tools/stable/generated/mne.Epochs.html&gt;`_
    and `EDF &lt;https://www.edfplus.info/&gt;`_.


    Parameters
    ----------
    filename
        Path with the location of the hdf file.
    offset_correction
       The header will store the offset (based on ntp) at start and end of
       acquisition, this values can be used to perform an offset correction.
    &quot;&quot;&quot;

    # ----------------------------------------------------------------------
    def __init__(self, filename: str, offset_correction: bool = True) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.filename = filename
        self.offset_correction = offset_correction
        self._open()

    # ----------------------------------------------------------------------
    def __repr__(self):
        &quot;&quot;&quot;&quot;&quot;&quot;
        info = &quot;=&quot; * 50
        info += f&quot;\n{self.filename}\n&quot;
        info += str(datetime.fromtimestamp(self.header[&#39;datetime&#39;]))
        info += &#39;\n&#39; + &quot;=&quot; * 50 + &#39;\n&#39;
        info += f&#39;MARKERS: {list(self.markers.keys())}\n&#39;
        for k in self.header:
            info += f&quot;{k.upper()}: {self.header[k]}\n&quot;
        info += &quot;=&quot; * 50
        return info

    # ----------------------------------------------------------------------
    @cached_property
    def header(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;The header of the hdf file.&quot;&quot;&quot;
        header = json.loads(self.f.root.header[0])
        header.update(json.loads(self.f.root.header[1]))
        if &#39;channels&#39; in header:
            header[&#39;channels&#39;] = {int(k): header[&#39;channels&#39;][k]
                                  for k in header[&#39;channels&#39;]}
        return header

    # ----------------------------------------------------------------------
    @cached_property
    def eeg(self) -&gt; np.ndarray:
        &quot;&quot;&quot;The EEG data of the hdf file in the shape of (`channels, time`).&quot;&quot;&quot;
        return np.array(self.f.root.eeg_data).T

    # ----------------------------------------------------------------------
    @cached_property
    def aux(self) -&gt; np.ndarray:
        &quot;&quot;&quot;The AUX data of the hdf file in the shape of (`aux, time`).&quot;&quot;&quot;
        return np.array(self.f.root.aux_data).T

    # ----------------------------------------------------------------------
    @cached_property
    def annotations(self) -&gt; list:
        &quot;&quot;&quot;A list of annotations.

        The `HDF5Writer` write the annotations with timestamps, but `EDF` needs
        the relative time from start in seconds.
        &quot;&quot;&quot;

        if not hasattr(self.f.root, &#39;annotations&#39;):
            return []

        anotations = [json.loads(an) for an in self.f.root.annotations]
        start = datetime.fromtimestamp(self.timestamp[0])

        for index, an in enumerate(anotations):
            onset = (datetime.fromtimestamp(an[0]) - start).total_seconds()
            anotations[index][0] = onset

        return anotations

    # ----------------------------------------------------------------------
    @cached_property
    def markers(self) -&gt; Dict[str, List[timestamp_]]:
        &quot;&quot;&quot;A dictionary with the markers and timestamps as values.&quot;&quot;&quot;

        if not hasattr(self.f.root, &#39;markers&#39;):
            return {}

        markers = {}
        for mkr in self.f.root.markers:
            t, marker = json.loads(mkr)
            markers.setdefault(marker, []).append(t - self.offset)

        return markers

    # ----------------------------------------------------------------------
    @cached_property
    def markers_relative(self) -&gt; Dict[str, List[int]]:
        &quot;&quot;&quot;A dictionary with the markers and milliseconds as values.&quot;&quot;&quot;
        markers_relative = {}
        for key in self.markers:
            locs = self.markers[key]
            markers_relative[key] = [self.timestamp_relative[np.abs(
                self.timestamp - loc).argmin()] for loc in locs]

        return markers_relative

    # ----------------------------------------------------------------------
    @cached_property
    def timestamp(self) -&gt; List[timestamp_]:
        &quot;&quot;&quot;A list of timestamps for EEG data.&quot;&quot;&quot;
        return self._timestamp(self.eeg.shape[1]) - self.offset

    # ----------------------------------------------------------------------
    @cached_property
    def timestamp_relative(self, fast=False) -&gt; List[int]:
        &quot;&quot;&quot;A list of timestamps in milliseconds.

        If `fast` the a simple relation between sample rate and data length is
        calculate instead.
        &quot;&quot;&quot;

        if fast:
            return np.linspace(0, (self.eeg.shape[1] / self.header[&#39;sample_rate&#39;]) * 1000, self.eeg.shape[1])
        else:
            m = (self.timestamp - self.timestamp[0]) * 1e3
            return np.array(np.round(m), dtype=int)

    # ----------------------------------------------------------------------
    @cached_property
    def classes(self):
        &quot;&quot;&quot;A list with the same length of EEG with markers as numbers.&quot;&quot;&quot;
        classes = np.zeros(self.timestamp_relative.shape)
        for marker in self.markers_relative:
            classes[self.markers_relative[marker]
                    ] = self.classes_indexes[marker]
        return classes

    # ----------------------------------------------------------------------
    @cached_property
    def aux_timestamp_(self) -&gt; List[timestamp_]:
        &quot;&quot;&quot;A list of timestamps for AUX data.&quot;&quot;&quot;
        return self._timestamp(self.aux.shape[1])

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Reader._timestamp"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Reader._timestamp">[docs]</a>    def _timestamp(self, length: int) -&gt; List[timestamp_]:
        &quot;&quot;&quot;Interpolate the timestamps in the case of zeros in it.&quot;&quot;&quot;
        timestamp = self.f.root.timestamp

        if timestamp[timestamp == 0].size &gt; 0:
            timestamp = interpolate_datetime(timestamp, length)

        return timestamp</div>

    # ----------------------------------------------------------------------
    @cached_property
    def classes_indexes(self) -&gt; Dict[str, int]:
        &quot;&quot;&quot;The standard for classes and indexes.&quot;&quot;&quot;
        return {key: (i + 1) for i, key in enumerate(self.markers.keys())}

    # ----------------------------------------------------------------------
    def __enter__(self) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        return self

    # ----------------------------------------------------------------------
    def _open(self) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.f = tables.open_file(self.filename, mode=&#39;r&#39;)

    # ----------------------------------------------------------------------
    def __exit__(self, exc_type: Text, exc_val: Text, exc_tb: Text) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.f.close()

    # ----------------------------------------------------------------------
    def close(self) -&gt; None:
        &quot;&quot;&quot;&quot;&quot;&quot;
        self.f.close()

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Reader.get_epochs"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Reader.get_epochs">[docs]</a>    def get_epochs(self, duration: int, tmin: Optional[int] = 0, markers: Union[None, List[str]] = None, **kwargs) -&gt; mne.EpochsArray:
        &quot;&quot;&quot;Create an `EpochsArray` object with the `MNE` library.

        This method auto crop the data in regard to markers also will drop
        channels that no correspond with the montage. For an example of use
        refer to `Data storage handler - MNE objects&lt;../notebooks/07-data_storage_handler.html#MNE-objects&gt;`_

        Parameters
        ----------
        duration
            The duration of the trial.
        tmin
            The time to take previous to the marker.
        markers
            A filter of markers for crop the signal.
        kwargs
            Optional arguments passed to `EpochsArray &lt;https://mne.tools/stable/generated/mne.EpochsArray.html&gt;`_

        Returns
        -------
        epochs
            An MNE Epochs object.
        &quot;&quot;&quot;

        if &#39;montage&#39; in self.header:
            montage = self.header[&#39;montage&#39;]
        else:
            logging.error(&quot;&#39;montage&#39; must be defined in the header.&quot;)
            return

        if &#39;channels&#39; in self.header:
            channels = list(self.header[&#39;channels&#39;].values())
        else:
            logging.error(&quot;&#39;channels&#39; must be defined in the header.&quot;)
            return

        if &#39;sample_rate&#39; in self.header:
            sampling_rate = self.header[&#39;sample_rate&#39;]
        else:
            logging.error(&quot;&#39;sample_rate&#39; must be defined in the header.&quot;)
            return

        # Remove channels that not correspond with the montage
        montage = mne.channels.make_standard_montage(montage)
        channels_names = set(channels).intersection(
            set(montage.ch_names))
        channels_missings = set(channels).difference(
            set(montage.ch_names))

        if channels_missings:
            logging.warning(
                f&quot;Missing {channels_missings} channels in {montage} montage.\n&quot;
                f&quot;Missing channels will be removed from MNE Epochs&quot;)

        info = mne.create_info(
            list(channels_names), sfreq=sampling_rate, ch_types=&quot;eeg&quot;)
        info.set_montage(montage)

        if markers is None:
            markers = self.classes_indexes.keys()

        classes = []
        data = []
        for class_ in markers:
            starts = self.markers_relative[class_]
            classes.extend([class_] * len(starts))
            data.extend([self.eeg[:, int(start + (tmin) * sampling_rate):int(start +
                                                                             (tmin + duration) * sampling_rate)] for start in starts])

        event_id = {mk: self.classes_indexes[mk] for mk in markers}
        events = [[i, 1, event_id[cls]] for i, cls in enumerate(classes)]

        return mne.EpochsArray(np.array(data), info, events=events, tmin=tmin, event_id=event_id, **kwargs)</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Reader.to_edf"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Reader.to_edf">[docs]</a>    def to_edf(self, filename: str) -&gt; None:
        &quot;&quot;&quot;Export to EDF file.&quot;&quot;&quot;

        if &#39;sample_rate&#39; in self.header:
            sampling_rate = self.header[&#39;sample_rate&#39;]
        else:
            logging.error(&quot;&#39;sample_rate&#39; must be defined in the header.&quot;)
            return

        edf_channel_info = []
        edf_data_list = []

        for i, channel in enumerate(self.header[&#39;channels&#39;]):
            data = self.eeg[i]
            if data.max() == data.min():
                max_, min_ = 1, -1
            else:
                max_, min_ = data.max(), data.min()
            channel = {
                &#39;label&#39;: f&quot;ch{i+1} - {self.header[&#39;channels&#39;][channel]}&quot;,
                &#39;dimension&#39;: &#39;uV&#39;,
                &#39;sample_rate&#39;: sampling_rate,
                &#39;physical_max&#39;: max_,
                &#39;physical_min&#39;: min_,
                &#39;digital_max&#39;: 2 ** 12,
                &#39;digital_min&#39;: -2 ** 12,
                &#39;transducer&#39;: &#39;&#39;,
                &#39;prefilter&#39;: &#39;&#39;,
            }
            edf_channel_info.append(channel)
            edf_data_list.append(data)

        for i, aux in enumerate(self.aux):
            if aux.max() == aux.min():
                max_, min_ = 1, -1
            else:
                max_, min_ = aux.max(), aux.min()
            channel = {
                &#39;label&#39;: f&quot;aux{i+1}&quot;,
                &#39;dimension&#39;: &#39;&#39;,
                &#39;sample_rate&#39;: sampling_rate,
                &#39;physical_max&#39;: max_,
                &#39;physical_min&#39;: min_,
                &#39;digital_max&#39;: 2 ** 12,
                &#39;digital_min&#39;: -2 ** 12,
                &#39;transducer&#39;: &#39;&#39;,
                &#39;prefilter&#39;: &#39;&#39;,
            }
            edf_channel_info.append(channel)
            edf_data_list.append(aux)

        if self.markers:
            channel = {
                &#39;label&#39;: f&quot;classes&quot;,
                &#39;dimension&#39;: &#39;&#39;,
                &#39;sample_rate&#39;: sampling_rate,
                &#39;physical_max&#39;: max(self.classes_indexes.values()),
                &#39;physical_min&#39;: min(self.classes_indexes.values()),
                &#39;digital_max&#39;: 2 ** 12,
                &#39;digital_min&#39;: -2 ** 12,
                &#39;transducer&#39;: &#39;&#39;,
                &#39;prefilter&#39;: &#39;&#39;,
            }
            edf_channel_info.append(channel)
            edf_data_list.append(self.classes)

        header = {
            &#39;admincode&#39;: self.header.get(&#39;admincode&#39;, &#39;&#39;),
            &#39;birthdate&#39;: self.header.get(&#39;birthdate&#39;, date(1991, 2, 8)),
            &#39;equipment&#39;: self.header.get(&#39;equipment&#39;, &#39;&#39;),
            &#39;gender&#39;: self.header.get(&#39;gender&#39;, 0),
            &#39;patientcode&#39;: self.header.get(&#39;patientcode&#39;, &#39;&#39;),
            &#39;patientname&#39;: self.header.get(&#39;patientname&#39;, &#39;&#39;),
            &#39;patient_additional&#39;: self.header.get(&#39;patient_additional&#39;, &#39;&#39;),
            &#39;recording_additional&#39;: self.header.get(&#39;recording_additional&#39;, &#39;&#39;),
            &#39;startdate&#39;: datetime.fromtimestamp(self.timestamp[0]),
            &#39;technician&#39;: self.header.get(&#39;technician&#39;, &#39;&#39;),
        }

        f = pyedflib.EdfWriter(filename, len(
            edf_channel_info), file_type=pyedflib.FILETYPE_EDFPLUS)

        f.setHeader(header)
        f.setSignalHeaders(edf_channel_info)
        f.writeSamples(edf_data_list)

        for annotation in self.annotations:
            f.writeAnnotation(*annotation)
        f.close()</div>

    # ----------------------------------------------------------------------
<div class="viewcode-block" id="HDF5Reader.get_data"><a class="viewcode-back" href="../../openbci_stream.utils.hdf5.html#openbci_stream.utils.hdf5.HDF5Reader.get_data">[docs]</a>    def get_data(self, duration: int, tmin: Optional[int] = 0, markers: Union[None, List[str]] = None, **kwargs) -&gt; Tuple[np.ndarray]:
        &quot;&quot;&quot;Create an `EpochsArray` object with the `MNE` library.

        This method auto crop the data in regard to markers also will drop
        channels that no correspond with the montage. For an example of use
        refer to `Data storage handler - MNE objects&lt;../notebooks/07-data_storage_handler.html#MNE-objects&gt;`_

        Parameters
        ----------
        duration
            The duration of the trial.
        tmin
            The time to take previous to the marker.
        markers
            A filter of markers for crop the signal.
        kwargs
            Optional arguments passed to `EpochsArray &lt;https://mne.tools/stable/generated/mne.EpochsArray.html&gt;`_

        Returns
        -------
        trials
            Dataset with the shape (`trials`, `channels`, `time`)
        classes
            List of classes
        &quot;&quot;&quot;

        epochs = self.get_epochs(duration, tmin, markers)
        return epochs._data, epochs.events[:, 2]</div>

    # ----------------------------------------------------------------------
    @cached_property
    def offset(self) -&gt; float:
        &quot;&quot;&quot;Calculate the timestamps offset in seconds.&quot;&quot;&quot;
        if self.offset_correction and &#39;start-offset&#39; in self.header and &#39;end-offset&#39; in self.header:
            start, end = self.header[&#39;start-offset&#39;], self.header[&#39;end-offset&#39;]
            return (start + (start - end) / self.header[&#39;shape&#39;][1]) / 1000
        else:
            if self.offset_correction:
                logging.warning(&#39;No offsets values to perform correction&#39;)
            return 0</div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/logo.svg" alt="Logo"/>
            </a></p>
<h3><a href="../../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/00-installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/01-hardware_configurations.html">Hardware configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/02-kafka_configuration.html">Kafka configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/03-data_acquisition.html">Data Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/04-board_modes.html">Board modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/05-stream_markers.html">Stream markers with Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/06-command_line_interface.html">Command line interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/07-data_storage_handler.html">Data storage handler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/A1-raw_cleaning.html">Appendix 1 - Raw data processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/A2-electrodes_impedance.html">Appendix 2 - Measuring Electrode Impedance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/A3-server-based_acquisition.html">Appendix 3 - Raspberry PI as server acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/A4-latencies.html">Appendix 4 - System latencies</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019-2021, Yeison Cardona.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>